{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetstream_hugo.definitions import *\n",
    "from jetstream_hugo.plots import *\n",
    "from jetstream_hugo.data import *\n",
    "from jetstream_hugo.anyspell import *\n",
    "from jetstream_hugo.jet_finding import *\n",
    "from jetstream_hugo.clustering import *\n",
    "import geopandas as gpd\n",
    "\n",
    "import intake\n",
    "\n",
    "import colormaps\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arco-era5 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "def _compute(obj, progress: bool = False, **kwargs):\n",
    "    kwargs = COMPUTE_KWARGS | kwargs\n",
    "    try:\n",
    "        if progress:\n",
    "            with ProgressBar():\n",
    "                return obj.compute(**kwargs)\n",
    "        else:\n",
    "            return obj.compute(**kwargs)\n",
    "    except AttributeError:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_zarr(\n",
    "    'gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3',\n",
    "    chunks=None,\n",
    "    storage_options=dict(token='anon'),\n",
    ")\n",
    "ar_full_37_1h = ds.sel(time=slice(ds.attrs['valid_time_start'], ds.attrs['valid_time_stop']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ds = ar_full_37_1h[[\"u_component_of_wind\", \"v_component_of_wind\"]].sel(time=ar_full_37_1h.time.dt.hour % 6 == 0, latitude=ar_full_37_1h.latitude >= 0, level=[175,  200,  225,  250,  300,  350]).isel(longitude=slice(None, None, 2), latitude=slice(None, None, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(f\"/storage/workspaces/giub_meteo_impacts/ci01/ERA5/plev/flat_wind/dailymean\")\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def downloader(base_ds, base_path, month, year):\n",
    "    month_str = str(month).zfill(2)\n",
    "    opath = base_path.joinpath(f\"{year}{month_str}.nc\")\n",
    "    if opath.is_file():\n",
    "        return f\"Already had {year}{month}\"\n",
    "    ds = _compute(base_ds.sel(time=(base_ds.time.dt.year==year) & (base_ds.time.dt.month==month)), progress=True)\n",
    "    ds = standardize(ds)\n",
    "    ds[\"s\"] = np.sqrt(ds[\"u\"] ** 2 + ds[\"v\"] ** 2)\n",
    "    ds = flatten_by(ds, \"s\")\n",
    "    ds.to_netcdf(opath)\n",
    "    return f\"Completed {year}{month}\"\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    futures = [\n",
    "        executor.submit(downloader, base_ds.copy(), base_path, month, year) for year in YEARS for month in range(1, 13)\n",
    "    ]\n",
    "    for f in as_completed(futures):\n",
    "        try:\n",
    "            print(f.result())\n",
    "        except:\n",
    "            print(\"could not retrieve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = {\n",
    "    \"t2m\": \"2m_temperature\",\n",
    "    \"mslp\": \"mean_sea_level_pressure\",\n",
    "    \"sst\": \"sea_surface_temperature\",\n",
    "    \"tp\": \"total_precipitation\",\n",
    "}\n",
    "for key, val in varnames.items():\n",
    "    base_da = ar_full_37_1h[val].sel(time=ar_full_37_1h.time.dt.hour % 6 == 0, latitude=ar_full_37_1h.latitude >= 0)[:, ::2, ::2]\n",
    "    base_path = Path(f\"/storage/workspaces/giub_meteo_impacts/ci01/ERA5/surf/{key}/dailymean\")\n",
    "    print(base_path)\n",
    "    for year in tqdm(YEARS):\n",
    "        opath = base_path.joinpath(f\"{year}.nc\")\n",
    "        if opath.is_file():\n",
    "            da = xr.open_dataarray(opath)\n",
    "            da = standardize(da)\n",
    "        else:\n",
    "            da = _compute(base_da.sel(time=base_da.time.dt.year==year), progress=True).resample(time=\"1D\").mean()\n",
    "        da.to_netcdf(opath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climatologies, datahandlers of new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_all_smoothed_anomalies(\"ERA5\", \"surf\", \"t2m\", \"dailymean\", 'dayofyear', {'dayofyear': ('win', 15)}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_all_smoothed_anomalies(\"ERA5\", \"surf\", \"tp\", \"dailymean\", 'dayofyear', {'dayofyear': ('win', 15)}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_all_smoothed_anomalies(\"ERA5\", \"surf\", \"sst\", \"dailymean\", 'dayofyear', {'dayofyear': ('win', 15)}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_all_smoothed_anomalies(\"ERA5\", \"surf\", \"mslp\", \"dailymean\", 'dayofyear', {'dayofyear': ('win', 15)}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_all_smoothed_anomalies(\"ERA5\", \"thetalev\", \"apvs\", \"dailymean\", 'dayofyear', {'dayofyear': ('win', 15)}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_all_smoothed_anomalies(\"ERA5\", \"thetalev\", \"cpvs\", \"dailymean\", 'dayofyear', {'dayofyear': ('win', 15)}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in tqdm(YEARS):\n",
    "    da = open_da(\"ERA5\", \"thetalev\", \"apvs\", \"6H\", period=[year])\n",
    "    da = compute(da.chunk({\"lev\": 1}).resample(time=\"1d\").mean(), progress_flag=True)\n",
    "    da.to_netcdf(data_path(\"ERA5\", \"thetalev\", \"apvs\", \"dailymean\").joinpath(f\"{year}.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in tqdm(YEARS):\n",
    "    da = open_da(\"ERA5\", \"plev\", \"z\", \"6H\", period=[year])\n",
    "    da = compute(da.chunk({\"lev\": 1}).resample(time=\"1d\").mean(), progress_flag=True)\n",
    "    da.to_netcdf(data_path(\"ERA5\", \"plev\", \"z\", \"dailymean\").joinpath(f\"{year}.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100.00% Completed | 38.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:39<01:18, 39.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100.00% Completed | 19.50 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:58<00:27, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100.00% Completed | 20.58 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:19<00:00, 26.56s/it]\n",
      "100%|██████████| 64/64 [00:28<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "compute_all_smoothed_anomalies(\"ERA5\", \"plev\", \"z\", \"dailymean\", 'dayofyear', {'dayofyear': ('win', 15)}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [20:55<00:00, 19.61s/it]\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm(YEARS):\n",
    "    da = open_da(\"ERA5\", \"thetalev\", \"cpvs\", \"6H\", period=[year])\n",
    "    da = compute(da.chunk({\"lev\": 1}).resample(time=\"1d\").mean(), progress_flag=False)\n",
    "    da.to_netcdf(data_path(\"ERA5\", \"thetalev\", \"cpvs\", \"dailymean\").joinpath(f\"{year}.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[######                                  ] | 17.19% Completed | 34.36 ss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/jetstream_hugo/src/jetstream_hugo/definitions.py:375\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(obj, progress_flag, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 375\u001b[0m     \u001b[43mclient\u001b[49m \u001b[38;5;66;03m# in globals\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m da_ \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m350\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jetstream_hugo/src/jetstream_hugo/definitions.py:380\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(obj, progress_flag, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_flag:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ProgressBar():\n\u001b[0;32m--> 380\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcompute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/site-packages/xarray/core/dataarray.py:1179\u001b[0m, in \u001b[0;36mDataArray.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03mremote source into memory and return a new array.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/site-packages/xarray/core/dataarray.py:1147\u001b[0m, in \u001b[0;36mDataArray.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    remote source into memory and return this array.\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1147\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable \u001b[38;5;241m=\u001b[39m new\u001b[38;5;241m.\u001b[39m_variable\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/site-packages/xarray/core/dataset.py:863\u001b[0m, in \u001b[0;36mDataset.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m chunkmanager \u001b[38;5;241m=\u001b[39m get_chunked_array_type(\u001b[38;5;241m*\u001b[39mlazy_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    862\u001b[0m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, Any], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlazy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data):\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[k]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/site-packages/xarray/namedarray/daskmanager.py:86\u001b[0m, in \u001b[0;36mDaskManager.compute\u001b[0;34m(self, *data, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mdata: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, _DType_co], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "da_ = compute(da.sel(lev=350), progress_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'da_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mda_\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'da_' is not defined"
     ]
    }
   ],
   "source": [
    "da_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "da_ = pl.from_pandas(da_.to_dataframe().reset_index()).cast({\"lat\": pl.Float32, \"lon\": pl.Float32, \"lev\": pl.UInt16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (190_788_480, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th><th>lat</th><th>lon</th><th>lev</th><th>apvs</th></tr><tr><td>datetime[ns]</td><td>f32</td><td>f32</td><td>u16</td><td>f32</td></tr></thead><tbody><tr><td>1960-01-01 00:00:00</td><td>0.0</td><td>-180.0</td><td>350</td><td>0.0</td></tr><tr><td>1960-01-01 00:00:00</td><td>0.0</td><td>-179.5</td><td>350</td><td>0.0</td></tr><tr><td>1960-01-01 00:00:00</td><td>0.0</td><td>-179.0</td><td>350</td><td>0.0</td></tr><tr><td>1960-01-01 00:00:00</td><td>0.0</td><td>-178.5</td><td>350</td><td>0.0</td></tr><tr><td>1960-01-01 00:00:00</td><td>0.0</td><td>-178.0</td><td>350</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1960-12-31 18:00:00</td><td>90.0</td><td>177.5</td><td>350</td><td>0.0</td></tr><tr><td>1960-12-31 18:00:00</td><td>90.0</td><td>178.0</td><td>350</td><td>0.0</td></tr><tr><td>1960-12-31 18:00:00</td><td>90.0</td><td>178.5</td><td>350</td><td>0.0</td></tr><tr><td>1960-12-31 18:00:00</td><td>90.0</td><td>179.0</td><td>350</td><td>0.0</td></tr><tr><td>1960-12-31 18:00:00</td><td>90.0</td><td>179.5</td><td>350</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (190_788_480, 5)\n",
       "┌─────────────────────┬──────┬────────┬─────┬──────┐\n",
       "│ time                ┆ lat  ┆ lon    ┆ lev ┆ apvs │\n",
       "│ ---                 ┆ ---  ┆ ---    ┆ --- ┆ ---  │\n",
       "│ datetime[ns]        ┆ f32  ┆ f32    ┆ u16 ┆ f32  │\n",
       "╞═════════════════════╪══════╪════════╪═════╪══════╡\n",
       "│ 1960-01-01 00:00:00 ┆ 0.0  ┆ -180.0 ┆ 350 ┆ 0.0  │\n",
       "│ 1960-01-01 00:00:00 ┆ 0.0  ┆ -179.5 ┆ 350 ┆ 0.0  │\n",
       "│ 1960-01-01 00:00:00 ┆ 0.0  ┆ -179.0 ┆ 350 ┆ 0.0  │\n",
       "│ 1960-01-01 00:00:00 ┆ 0.0  ┆ -178.5 ┆ 350 ┆ 0.0  │\n",
       "│ 1960-01-01 00:00:00 ┆ 0.0  ┆ -178.0 ┆ 350 ┆ 0.0  │\n",
       "│ …                   ┆ …    ┆ …      ┆ …   ┆ …    │\n",
       "│ 1960-12-31 18:00:00 ┆ 90.0 ┆ 177.5  ┆ 350 ┆ 0.0  │\n",
       "│ 1960-12-31 18:00:00 ┆ 90.0 ┆ 178.0  ┆ 350 ┆ 0.0  │\n",
       "│ 1960-12-31 18:00:00 ┆ 90.0 ┆ 178.5  ┆ 350 ┆ 0.0  │\n",
       "│ 1960-12-31 18:00:00 ┆ 90.0 ┆ 179.0  ┆ 350 ┆ 0.0  │\n",
       "│ 1960-12-31 18:00:00 ┆ 90.0 ┆ 179.5  ┆ 350 ┆ 0.0  │\n",
       "└─────────────────────┴──────┴────────┴─────┴──────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_.group_by(pl.col(\"time\").dt.ordinal_day(), pl.col(\"lat\"), pl.col(\"lon\")).agg(pl.col(\"apvs\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]2024-10-30 11:30:21,960 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:33771\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 2059, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 2869, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 1013, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:56810 remote=tcp://127.0.0.1:33771>: Stream is closed\n",
      "2024-10-30 11:30:26,346 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:43601\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 2059, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 2869, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 1013, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:59510 remote=tcp://127.0.0.1:43601>: Stream is closed\n",
      "2024-10-30 11:30:34,380 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 20.08 GiB -- Worker memory limit: 24.21 GiB\n",
      "2024-10-30 11:30:37,154 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:36777\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 230, in read\n",
      "    buffer = await read_bytes_rw(stream, buffer_nbytes)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 2059, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 2869, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 1013, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:50746 remote=tcp://127.0.0.1:36777>: Stream is closed\n",
      "2024-10-30 11:30:37,352 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 16.54 GiB -- Worker memory limit: 24.21 GiB\n",
      "2024-10-30 11:30:43,922 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 17.54 GiB -- Worker memory limit: 24.21 GiB\n",
      "2024-10-30 11:30:46,665 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 17.17 GiB -- Worker memory limit: 24.21 GiB\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/__init__.py\", line 23, in <module>\n",
      "    from distributed.actor import Actor, ActorFuture, BaseActorFuture\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/actor.py\", line 13, in <module>\n",
      "    from distributed.client import Future\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/client.py\", line 65, in <module>\n",
      "  0%|          | 0/11 [03:08<?, ?it/s]\n",
      "2024-10-30 11:30:58,301 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 5, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('groupby_nanmean-reduce-partial-57035dec009cfa2851df8bc7d4ecf2d7', 0, 0, 8))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,326 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 11))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,326 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 59, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "    from distributed.core import OKMessage\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 37, in <module>\n",
      "    from distributed import profile, protocol\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/protocol/__init__.py\", line 6, in <module>\n",
      "    from distributed.protocol.core import decompress, dumps, loads, maybe_compress, msgpack\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1138, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1078, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1507, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1479, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1615, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 147, in _path_stat\n",
      "KeyboardInterrupt\n",
      "2024-10-30 11:30:58,358 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 29))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,358 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 15, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,360 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 23))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,369 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 57, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,370 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 18))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,370 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 3, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,370 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 19, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,493 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 4, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,496 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 48, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,505 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 24))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,512 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 30, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:30:58,520 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 56, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 1019, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "2024-10-30 11:31:03,546 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 1019, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 11:30:21,507 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:33771 (pid=1471376) exceeded 95% memory budget. Restarting...\n",
      "2024-10-30 11:30:22,042 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:33771' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('array-c425aede2f8327a76e3f05f022d67563', 31), ('array-c425aede2f8327a76e3f05f022d67563', 21), ('array-c425aede2f8327a76e3f05f022d67563', 30), ('array-c425aede2f8327a76e3f05f022d67563', 20), ('array-c425aede2f8327a76e3f05f022d67563', 17), ('array-c425aede2f8327a76e3f05f022d67563', 16), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 11), 'original-open_dataset-dummy-6948b1c41422ef3c78662e232b699ee1', ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 4)} (stimulus_id='handle-worker-cleanup-1730284222.0420094')\n",
      "2024-10-30 11:30:22,225 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-10-30 11:30:26,116 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:43601 (pid=1471379) exceeded 95% memory budget. Restarting...\n",
      "2024-10-30 11:30:26,396 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:43601' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 3), 'original-open_dataset-dummy-dedbbca4e138338b3be18557999e497b', ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 48)} (stimulus_id='handle-worker-cleanup-1730284226.3945436')\n",
      "2024-10-30 11:30:26,554 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-10-30 11:30:36,904 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:36777 (pid=1471385) exceeded 95% memory budget. Restarting...\n",
      "2024-10-30 11:30:37,157 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:36777' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 58), ('array-c425aede2f8327a76e3f05f022d67563', 30), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 57), ('array-c425aede2f8327a76e3f05f022d67563', 4), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 15), ('array-c425aede2f8327a76e3f05f022d67563', 48), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 56), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 59)} (stimulus_id='handle-worker-cleanup-1730284237.1566575')\n",
      "2024-10-30 11:30:37,284 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-10-30 11:30:54,115 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:46265 (pid=1471359) exceeded 95% memory budget. Restarting...\n",
      "2024-10-30 11:30:54,296 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:46265' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('array-c425aede2f8327a76e3f05f022d67563', 11), ('array-c425aede2f8327a76e3f05f022d67563', 20), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 9), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 5), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 8), 'original-open_dataset-dummy-6948b1c41422ef3c78662e232b699ee1', ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 10)} (stimulus_id='handle-worker-cleanup-1730284254.2962277')\n",
      "2024-10-30 11:30:54,322 - distributed.nanny - WARNING - Restarting worker\n",
      "2024-10-30 11:30:58,352 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:45641' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 26), 'original-open_dataset-dummy-71f549ad29a9b8ecae23a56465227854'} (stimulus_id='handle-worker-cleanup-1730284258.3523855')\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-449399' coro=<Client._gather.<locals>.wait() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/client.py:2391> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/client.py\", line 2400, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "2024-10-30 11:30:58,465 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:44159' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('getitem-0613768fb2049deafe2a398abdb7bb32', 11, 0, 0), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 51), ('array-c425aede2f8327a76e3f05f022d67563', 20)} (stimulus_id='handle-worker-cleanup-1730284258.4639053')\n",
      "2024-10-30 11:30:58,477 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:38173' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 42), ('array-c425aede2f8327a76e3f05f022d67563', 29), ('getitem-0613768fb2049deafe2a398abdb7bb32', 29, 0, 0), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 43), ('array-c425aede2f8327a76e3f05f022d67563', 19)} (stimulus_id='handle-worker-cleanup-1730284258.475149')\n",
      "2024-10-30 11:30:58,579 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:33929' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 28), 'original-open_dataset-dummy-12d86dbf59e512448656d3b9f619f558', ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 41)} (stimulus_id='handle-worker-cleanup-1730284258.5770795')\n",
      "2024-10-30 11:30:58,593 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:40753' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('array-c425aede2f8327a76e3f05f022d67563', 31), ('getitem-0613768fb2049deafe2a398abdb7bb32', 31, 0, 0), ('getitem-0613768fb2049deafe2a398abdb7bb32', 18, 0, 0)} (stimulus_id='handle-worker-cleanup-1730284258.5913053')\n",
      "2024-10-30 11:30:58,618 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:41307' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 21, 0, 0), 'original-open_dataset-dummy-60c93c70b55950df923c1de8bbcedd39'} (stimulus_id='handle-worker-cleanup-1730284258.6025143')\n",
      "2024-10-30 11:30:58,633 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:33249' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'original-open_dataset-dummy-1a7a44c8fe6c393f5d19ab8fa273e517'} (stimulus_id='handle-worker-cleanup-1730284258.6321967')\n",
      "2024-10-30 11:30:58,657 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:44081' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('array-c425aede2f8327a76e3f05f022d67563', 56), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 6), ('array-c425aede2f8327a76e3f05f022d67563', 4), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 2), 'original-open_dataset-dummy-6734aa08debc02fe7f4ede956886f473', ('array-c425aede2f8327a76e3f05f022d67563', 3), ('array-c425aede2f8327a76e3f05f022d67563', 18)} (stimulus_id='handle-worker-cleanup-1730284258.655107')\n",
      "2024-10-30 11:30:58,678 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:39963' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 7), ('array-c425aede2f8327a76e3f05f022d67563', 11), ('array-c425aede2f8327a76e3f05f022d67563', 30), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 0), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 35), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 34), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 1), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 33)} (stimulus_id='handle-worker-cleanup-1730284258.676252')\n",
      "2024-10-30 11:30:58,699 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:33693' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'original-open_dataset-dummy-fe2604b28724c8136e73d9c78fe1333c', ('array-c425aede2f8327a76e3f05f022d67563', 22), ('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 22, 0, 0), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 27)} (stimulus_id='handle-worker-cleanup-1730284258.6973321')\n",
      "2024-10-30 11:30:58,711 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:34279' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 32), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 45), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 44), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 47), 'original-open_dataset-dummy-3f66aac412dcc832e3df60a0d7ce25e9', ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 46)} (stimulus_id='handle-worker-cleanup-1730284258.7096665')\n",
      "2024-10-30 11:30:58,831 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:38523' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('groupby_nanmean-reduce-partial-57035dec009cfa2851df8bc7d4ecf2d7', 0, 0, 9), ('array-c425aede2f8327a76e3f05f022d67563', 40), 'original-open_dataset-dummy-e9536067bb84824e825eb15f4e9f0cfc', ('array-c425aede2f8327a76e3f05f022d67563', 58), ('array-c425aede2f8327a76e3f05f022d67563', 25)} (stimulus_id='handle-worker-cleanup-1730284258.8312664')\n",
      "2024-10-30 11:30:58,879 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:38471' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 13), ('getitem-0613768fb2049deafe2a398abdb7bb32', 17, 0, 0), ('array-c425aede2f8327a76e3f05f022d67563', 17), ('array-c425aede2f8327a76e3f05f022d67563', 23), ('getitem-0613768fb2049deafe2a398abdb7bb32', 23, 0, 0), ('reindex_intermediates-354bdf9a4a7033ddf7ff979cd099de20', 0, 0, 49)} (stimulus_id='handle-worker-cleanup-1730284258.8794568')\n",
      "2024-10-30 11:30:58,905 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:38691' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('array-c425aede2f8327a76e3f05f022d67563', 48), ('array-c425aede2f8327a76e3f05f022d67563', 15), 'original-open_dataset-dummy-4a9b208e53635a11709945185e84475f'} (stimulus_id='handle-worker-cleanup-1730284258.9046464')\n",
      "2024-10-30 11:30:59,036 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:40883' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('groupby_nanmean-reduce-partial-57035dec009cfa2851df8bc7d4ecf2d7', 0, 0, 13), ('array-c425aede2f8327a76e3f05f022d67563', 21), ('array-c425aede2f8327a76e3f05f022d67563', 24), ('getitem-0613768fb2049deafe2a398abdb7bb32', 24, 0, 0), ('array-c425aede2f8327a76e3f05f022d67563', 57)} (stimulus_id='handle-worker-cleanup-1730284259.0359025')\n",
      "2024-10-30 11:30:59,075 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:41197' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('array-c425aede2f8327a76e3f05f022d67563', 59), 'original-open_dataset-dummy-295b8ee9be45971e80e0c571f511e8d0'} (stimulus_id='handle-worker-cleanup-1730284259.0749302')\n",
      "2024-10-30 11:31:01,616 - distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/jetstream_hugo/src/jetstream_hugo/definitions.py:375\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(obj, progress_flag, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 375\u001b[0m     \u001b[43mclient\u001b[49m \u001b[38;5;66;03m# in globals\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompute_all_smoothed_anomalies\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mERA5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthetalev\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapvs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m6H\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhourofyear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhourofyear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jetstream_hugo/src/jetstream_hugo/data.py:592\u001b[0m, in \u001b[0;36mcompute_all_smoothed_anomalies\u001b[0;34m(dataset, level_type, varname, resolution, clim_type, clim_smoothing, smoothing)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lev \u001b[38;5;129;01min\u001b[39;00m tqdm(da[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlev\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m    591\u001b[0m     da_ \u001b[38;5;241m=\u001b[39m extract_levels(da, lev)\n\u001b[0;32m--> 592\u001b[0m     clim \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_clim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mda_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclim_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m     clim \u001b[38;5;241m=\u001b[39m smooth(clim, clim_smoothing)\n\u001b[1;32m    594\u001b[0m     clims\u001b[38;5;241m.\u001b[39mappend(clim)\n",
      "File \u001b[0;32m~/jetstream_hugo/src/jetstream_hugo/data.py:514\u001b[0m, in \u001b[0;36mcompute_clim\u001b[0;34m(da, clim_type)\u001b[0m\n\u001b[1;32m    506\u001b[0m da, coord \u001b[38;5;241m=\u001b[39m assign_clim_coord(da, clim_type)\n\u001b[1;32m    507\u001b[0m clim \u001b[38;5;241m=\u001b[39m xarray_reduce(\n\u001b[1;32m    508\u001b[0m     da,\n\u001b[1;32m    509\u001b[0m     coord,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m     expected_groups\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(coord\u001b[38;5;241m.\u001b[39mvalues),\n\u001b[1;32m    513\u001b[0m )\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jetstream_hugo/src/jetstream_hugo/definitions.py:380\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(obj, progress_flag, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_flag:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ProgressBar():\n\u001b[0;32m--> 380\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcompute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/site-packages/xarray/core/dataarray.py:1179\u001b[0m, in \u001b[0;36mDataArray.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03mremote source into memory and return a new array.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/site-packages/xarray/core/dataarray.py:1147\u001b[0m, in \u001b[0;36mDataArray.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    remote source into memory and return this array.\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1147\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable \u001b[38;5;241m=\u001b[39m new\u001b[38;5;241m.\u001b[39m_variable\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/site-packages/xarray/core/dataset.py:863\u001b[0m, in \u001b[0;36mDataset.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m chunkmanager \u001b[38;5;241m=\u001b[39m get_chunked_array_type(\u001b[38;5;241m*\u001b[39mlazy_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    862\u001b[0m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, Any], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlazy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data):\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[k]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/site-packages/xarray/namedarray/daskmanager.py:86\u001b[0m, in \u001b[0;36mDaskManager.compute\u001b[0;34m(self, *data, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mdata: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, _DType_co], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniforge3/envs/env11_2/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 11:31:05,360 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('groupby_nanmean-reduce-partial-57035dec009cfa2851df8bc7d4ecf2d7', 0, 0, 15))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:31:05,362 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils_comm.py\", line 459, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils_comm.py\", line 438, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 1254, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 1013, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48476 remote=tcp://127.0.0.1:44227>: Stream is closed\n",
      "2024-10-30 11:31:05,364 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 16, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "2024-10-30 11:31:05,367 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1250, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils_comm.py\", line 459, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils_comm.py\", line 438, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 1254, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 1013, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48470 remote=tcp://127.0.0.1:44227>: Stream is closed\n",
      "2024-10-30 11:31:06,917 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name=\"execute(('concatenate-open_dataset-dummy-getitem-0613768fb2049deafe2a398abdb7bb32', 58, 0, 0))\" coro=<Worker.execute() done, defined at /storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker_state_machine.py:3615>> ended with CancelledError\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 1019, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 1019, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "2024-10-30 11:31:08,820 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 1019, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "2024-10-30 11:31:08,831 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 1019, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "2024-10-30 11:31:10,325 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 1019, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/spawn.py\", line 135, in _main\n",
      "    return self._bootstrap(parent_sentinel)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 332, in _bootstrap\n",
      "    threading._shutdown()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/threading.py\", line 1590, in _shutdown\n",
      "    lock.acquire()\n",
      "KeyboardInterrupt\n",
      "Process Dask Worker process (from Nanny):\n",
      "Process Dask Worker process (from Nanny):\n",
      "2024-10-30 11:31:10,472 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Process Dask Worker process (from Nanny):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 1019, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 993, in _run\n",
      "    with contextlib.ExitStack() as stack:\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/contextlib.py\", line 601, in __exit__\n",
      "    raise exc_details[1]\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/contextlib.py\", line 586, in __exit__\n",
      "    if cb(*exc_details):\n",
      "       ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/contextlib.py\", line 469, in _exit_wrapper\n",
      "    callback(*args, **kwds)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/threading.py\", line 1123, in join\n",
      "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 1019, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 1019, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "KeyboardInterrupt\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 993, in _run\n",
      "    with contextlib.ExitStack() as stack:\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/contextlib.py\", line 601, in __exit__\n",
      "    raise exc_details[1]\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/contextlib.py\", line 586, in __exit__\n",
      "    if cb(*exc_details):\n",
      "       ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/contextlib.py\", line 469, in _exit_wrapper\n",
      "    callback(*args, **kwds)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/threading.py\", line 1123, in join\n",
      "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 993, in _run\n",
      "    with contextlib.ExitStack() as stack:\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/contextlib.py\", line 601, in __exit__\n",
      "    raise exc_details[1]\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/contextlib.py\", line 586, in __exit__\n",
      "    if cb(*exc_details):\n",
      "       ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/contextlib.py\", line 469, in _exit_wrapper\n",
      "    callback(*args, **kwds)\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/threading.py\", line 1123, in join\n",
      "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "2024-10-30 11:31:10,473 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1521, in close\n",
      "    await self.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,478 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1644, in close\n",
      "    await asyncio.to_thread(\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,477 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1644, in close\n",
      "    await asyncio.to_thread(\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,481 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1644, in close\n",
      "    await asyncio.to_thread(\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,476 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1521, in close\n",
      "    await self.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,477 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1644, in close\n",
      "    await asyncio.to_thread(\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,475 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1644, in close\n",
      "    await asyncio.to_thread(\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,481 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1644, in close\n",
      "    await asyncio.to_thread(\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,520 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1644, in close\n",
      "    await asyncio.to_thread(\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,521 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1644, in close\n",
      "    await asyncio.to_thread(\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,475 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1521, in close\n",
      "    await self.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,521 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1521, in close\n",
      "    await self.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,522 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1521, in close\n",
      "    await self.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,522 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1521, in close\n",
      "    await self.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,522 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1521, in close\n",
      "    await self.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,523 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/nanny.py\", line 981, in run\n",
      "    await worker.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1644, in close\n",
      "    await asyncio.to_thread(\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,523 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1521, in close\n",
      "    await self.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "2024-10-30 11:31:10,523 - distributed.worker - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/compatibility.py\", line 204, in asyncio_run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
      "    event_list = self._selector.select(timeout)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/selectors.py\", line 468, in select\n",
      "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/utils.py\", line 837, in wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/worker.py\", line 1521, in close\n",
      "    await self.finished()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/site-packages/distributed/core.py\", line 489, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/storage/homefs/hb22g102/miniforge3/envs/env11_2/lib/python3.11/asyncio/locks.py\", line 213, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "compute_all_smoothed_anomalies(\"ERA5\", \"thetalev\", \"apvs\", \"6H\", 'hourofyear', {'hourofyear': ('win', 60)}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_all_smoothed_anomalies(\"ERA5\", \"thetalev\", \"cpvs\", \"6H\", 'hourofyear', {'hourofyear': ('win', 60)}, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new pvs das"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /storage/homefs/hb22g102/miniforge3/envs/env11_2/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "import polars_st as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_xarray(events: st.GeoDataFrame, dummy_da: xr.DataArray, varname: str):\n",
    "    dummy_da = dummy_da.rename(\"dummy\")\n",
    "    da_df = pl.from_pandas(dummy_da.to_dataframe().reset_index())\n",
    "    orig_times = da_df[\"time\"]\n",
    "    timedtype = orig_times.dtype\n",
    "    da_df = da_df.drop(\"time\", \"dummy\")\n",
    "    da_df = da_df.unique([\"lat\", \"lon\"]).sort([\"lat\", \"lon\"]).with_columns(geometry=st.from_xy(\"lon\", \"lat\"))\n",
    "    da_df = st.GeoDataFrame(da_df)\n",
    "    events = events.with_columns(pl.col(\"geometry\").st.buffer(0.25))\n",
    "    events = (\n",
    "        events.select([\"date\", \"geometry\", varname])\n",
    "        .cast({varname: pl.Float32})\n",
    "        .rename({\"date\": \"time\"})\n",
    "    )\n",
    "    events = events.cast({\"time\": timedtype})\n",
    "    events = events.filter(pl.col(\"time\").is_in(orig_times))\n",
    "    dummy_da = xr.zeros_like(dummy_da, dtype=np.float32)\n",
    "    events = events.st.sjoin(da_df, on=\"geometry\", how=\"inner\", predicate=\"contains\")\n",
    "    events = events.unique([\"time\", \"lon\", \"lat\"])\n",
    "    events_da = xr.DataArray.from_series(\n",
    "        events[[\"time\", varname, \"lat\", \"lon\"]]\n",
    "        .to_pandas()\n",
    "        .set_index([\"time\", \"lat\", \"lon\"])[varname]\n",
    "    ).fillna(0)\n",
    "    dummy_da.loc[\n",
    "        {\n",
    "            \"time\": events_da.time.values,\n",
    "            \"lat\": events_da.lat.values,\n",
    "            \"lon\": events_da.lon.values,\n",
    "        }\n",
    "    ] = events_da\n",
    "    return dummy_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:47<00:00,  4.30s/it]\n"
     ]
    }
   ],
   "source": [
    "all_events = {}\n",
    "for level in trange(310, 365, 5):\n",
    "    events = st.from_geopandas(gpd.read_parquet(f\"/storage/workspaces/giub_meteo_impacts/ci01/ERA5/RWB_index/era5_pv_streamers_{level}K_1959-2022.parquet\"))\n",
    "\n",
    "    tropospheric = events.filter(pl.col(\"mean_var\") < pl.col(\"level\"))\n",
    "    anticyclonic = tropospheric.filter(pl.col(\"intensity\") >= pl.col(\"level\"))\n",
    "    cyclonic = tropospheric.filter(pl.col(\"intensity\") < pl.col(\"level\"))\n",
    "    \n",
    "    all_events[level] = {\"anti\": anticyclonic, \"cycl\": cyclonic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [05:58<00:00, 32.56s/it]\n",
      "100%|██████████| 11/11 [05:59<00:00, 32.69s/it]\n",
      "100%|██████████| 11/11 [05:57<00:00, 32.51s/it]\n",
      "100%|██████████| 11/11 [05:56<00:00, 32.43s/it]\n",
      "100%|██████████| 11/11 [06:27<00:00, 35.21s/it]\n",
      "100%|██████████| 11/11 [08:10<00:00, 44.63s/it]\n",
      "100%|██████████| 11/11 [08:26<00:00, 46.03s/it]\n",
      "100%|██████████| 11/11 [08:44<00:00, 47.69s/it]\n"
     ]
    }
   ],
   "source": [
    "for year in YEARS:\n",
    "    # for month in range(1, 13):\n",
    "    ofile_anti = Path(f\"{DATADIR}/ERA5/thetalev/apvs/6H/{year}.nc\")\n",
    "    ofile_cycl = Path(f\"{DATADIR}/ERA5/thetalev/cpvs/6H/{year}.nc\")\n",
    "    if ofile_cycl.is_file() and ofile_anti.is_file():\n",
    "        continue\n",
    "    time_mask = (TIMERANGE.year == year)# & (TIMERANGE.month == month)\n",
    "    coords = {\n",
    "        \"time\": TIMERANGE[time_mask],\n",
    "        \"lat\": np.arange(0, 90.5, .5),\n",
    "        \"lon\": np.arange(-180, 180, .5),\n",
    "    }\n",
    "    shape = [len(co) for co in coords.values()]\n",
    "    dummy_da = xr.DataArray(np.zeros(shape), coords=coords)\n",
    "    anti_all_levs = {}\n",
    "    cycl_all_levs = {}\n",
    "    for lev, events in tqdm(all_events.items(), total=11):\n",
    "        anti_all_levs[lev] = to_xarray(events[\"anti\"], dummy_da, \"intensity\")\n",
    "        cycl_all_levs[lev] = to_xarray(events[\"cycl\"], dummy_da, \"intensity\")\n",
    "    anti_all_levs = xr.concat(anti_all_levs.values(), dim=\"lev\").assign_coords(lev=list(anti_all_levs))\n",
    "    cycl_all_levs = xr.concat(cycl_all_levs.values(), dim=\"lev\").assign_coords(lev=list(cycl_all_levs))\n",
    "    anti_all_levs.to_netcdf(ofile_anti)\n",
    "    cycl_all_levs.to_netcdf(ofile_cycl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CESM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "basepath = Path(\"/storage/workspaces/giub_meteo_impacts/ci01/CESM2/flat_wind\")\n",
    "paths = list(basepath.iterdir())\n",
    "paths = [path for path in paths if path.suffix == \".nc\" and path.name != \"ds.nc\"]\n",
    "parts = [path.name.split(\".\")[0].split(\"-\") for path in paths]\n",
    "parts = np.asarray(parts)\n",
    "sorted_order = np.argsort([memb.replace(\"r10\", \"r0\") for memb in parts[:, 0]])\n",
    "parts = parts[sorted_order]\n",
    "paths = [paths[i] for i in sorted_order]\n",
    "all_members = np.unique(parts[:, 0])\n",
    "all_years = np.unique(parts[:, 1])\n",
    "\n",
    "not_here = []\n",
    "here = []\n",
    "for year in all_years:\n",
    "    for member in all_members:\n",
    "        potential_path = basepath.joinpath(f\"{member}-{year}.nc\")\n",
    "        if potential_path.is_file():\n",
    "            here.append(potential_path)\n",
    "        else:\n",
    "            not_here.append(potential_path)\n",
    "len(here)\n",
    "\n",
    "from itertools import groupby\n",
    "paths_to_load = []\n",
    "valid_ensembles = []\n",
    "for key, indices in groupby(range(len(parts)), lambda i: parts[i][0]):\n",
    "    indices = list(indices)\n",
    "    group = parts[indices]\n",
    "    these_paths = [paths[i] for i in indices]\n",
    "    years = np.asarray(list([g[1] for g in group]))\n",
    "    if len(years) == 60:\n",
    "        paths_to_load.append(these_paths)\n",
    "        valid_ensembles.append(key)\n",
    "    else:\n",
    "        print(key, len(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "ds = []\n",
    "for ptl in tqdm(paths_to_load):\n",
    "    ds_ = []\n",
    "    for p in ptl:\n",
    "        this = xr.open_dataset(p)\n",
    "        this = this.reset_coords(\"time_bnds\", drop=True).drop_dims(\"nbnd\")\n",
    "        ds_.append(this)\n",
    "    ds.append(xr.concat(ds_, dim=\"time\"))\n",
    "ds = xr.concat(ds, dim=\"member\")\n",
    "# ds = xr.concat([xr.concat([xr.open_dataset[ptl_] for ptl_ in ptl], dim=\"time\") for ptl in paths_to_load], dim=\"member\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import progress, Client\n",
    "from jetstream_hugo.definitions import COMPUTE_KWARGS\n",
    "client = Client(**COMPUTE_KWARGS)\n",
    "dask.persist(ds)\n",
    "progress(ds, notebook=False)\n",
    "ds = dask.compute(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[0]\n",
    "to_comp = ds.to_zarr(f\"/storage/workspaces/giub_meteo_impacts/ci01/CESM2/flat_wind/ds.zarr\", compute=False, encoding={var: {\"chunks\": (-1, 100, -1, -1)} for var in ds.data_vars}, mode=\"w\")\n",
    "dask.persist(to_comp)\n",
    "progress(to_comp, notebook=False)\n",
    "dask.compute(to_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extreme cesm clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jetstream_hugo.data import *\n",
    "quantiles = ds[\"s\"].quantile(np.arange(0.6, 1, 0.05), [\"member\", \"lon\", \"lat\"]).compute()\n",
    "quantiles = smooth(quantiles, {\"time\": (\"win\", 15)}).load()\n",
    "quantiles.to_netcdf(f\"{DATADIR}/CESM2/flat_wind/results/s_q.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import DateFormatter, MonthLocator\n",
    "from jetstream_hugo.definitions import *\n",
    "from scipy.stats import linregress\n",
    "\n",
    "def get_trend(da):\n",
    "    years = np.unique(da.time.dt.year)\n",
    "    if \"jet\" not in da.dims:\n",
    "        result = linregress(years, da.values)\n",
    "        return xr.Dataset({\"slope\": result.slope, \"p\": result.pvalue})\n",
    "    jets = da.jet.values\n",
    "    slopes = xr.DataArray(np.zeros(len(jets)), coords={\"jet\": jets})\n",
    "    pvalues = slopes.copy()\n",
    "    for j, jet in enumerate(jets):\n",
    "        result = linregress(years, da.isel(jet=j).values)\n",
    "        slopes[j] = result.slope\n",
    "        pvalues[j] = result.pvalue\n",
    "    return xr.Dataset({\"slope\": slopes, \"p\": pvalues})\n",
    "\n",
    "winsize = 15\n",
    "halfwinsize = int(np.ceil(winsize / 2))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for q, qval in zip(quantiles[::2], np.arange(0.6, 1, 0.05 * 2)):\n",
    "    gb = q.groupby(\"time.dayofyear\")\n",
    "    x = list(gb.groups)\n",
    "    x = DATERANGE[x]\n",
    "    ys = gb.map(get_trend) \n",
    "    ps = ys[\"p\"]\n",
    "    ys = ys[\"slope\"]\n",
    "    ys = ys.pad({\"dayofyear\": halfwinsize}, mode=\"wrap\")\n",
    "    ys = ys.rolling(dayofyear=winsize, center=True).mean()\n",
    "    ys = ys.isel({\"dayofyear\": slice(halfwinsize, -halfwinsize)})\n",
    "    ax.plot(x, ys, label=f\"$q={qval:.1f}$\", lw=2)\n",
    "ax.grid(True)\n",
    "ax.xaxis.set_major_locator(MonthLocator(range(0, 13, 3)))\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"1 %b\"))\n",
    "ax.set_xlim(min(x), max(x))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_clim = compute_clim(quantiles, \"dayofyear\")\n",
    "q_clim = smooth(q_clim, {\"dayofyear\": (\"win\", 61)}).load()\n",
    "q_clim.to_netcdf(f\"{DATADIR}/CESM2/flat_wind/results/s_q_clim.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.reset_coords(\"time_bnds\", drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tp = ExtremeExperiment(\n",
    "    DataHandler(\"ERA5\", \"surf\", \"tp\", \"6H\", \"all\", \"JJA\", -30, 40, 30, 75, 250, 'hourofyear', {'hourofyear': ('win', 4 * 15)}, None),\n",
    "    q = 0.95,\n",
    ")\n",
    "da_tp = exp_tp.da.load()\n",
    "\n",
    "data_handlers = {}\n",
    "for varname in [\"u\", \"v\", \"s\"]:\n",
    "    dh = DataHandler(\"ERA5\", \"plev\", varname, \"6H\", \"all\", None, -80, 40, 15, 80, [175, 200, 225, 250, 300, 350], reduce_da=False)\n",
    "    data_handlers[varname] = dh\n",
    "exp = MultiVarExperiment(data_handlers)\n",
    "\n",
    "all_jets_one_df, where_are_jets, all_jets_one_array, all_jets_over_time, flags = exp.track_jets()\n",
    "props_as_ds = exp.props_as_ds(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdiff import DeepHash\n",
    "DeepHash(load_pickle(\"/storage/workspaces/giub_meteo_impacts/ci01/ERA5/surf/tp/6H/hourofyear_hourofyearwin60/results/1/predictions/1/metadata.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = [\"mean_lon\", \"mean_lat\", \"mean_lev\", \"spe_star\", \"width\", \"wavinessR16\", \"persistence\", \"com_speed\", \"int\"]\n",
    "predictors = prepare_predictors(\n",
    "    props_as_ds,\n",
    "    subset=subset,\n",
    "    anomalize=True,\n",
    "    normalize=True,\n",
    "    detrend=True,\n",
    "    nan_method=\"nearest\",\n",
    "    season=\"JJA\",\n",
    ")\n",
    "time_before = pd.Timedelta(0, \"D\")\n",
    "n_clu = 22\n",
    "clusters_da = exp_tp.spatial_clusters_as_da(n_clu)\n",
    "targets, length_targets, all_spells_ts, all_spells = exp_tp.create_targets(n_clu, 0.95, minlen=np.timedelta64(1, \"D\"))\n",
    "binary_targets = length_targets > 0\n",
    "masked_predictors = mask_from_spells_multi_region(predictors, targets, all_spells_ts, all_spells, time_before=time_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu = Clusterplot(1, 1, exp_tp.region)\n",
    "cmap = colormaps.BlAqGrYeOrReVi200\n",
    "ax = clu.axes[0]\n",
    "unique_clusters = np.arange(n_clu)\n",
    "norm = BoundaryNorm(np.concatenate([[-1], unique_clusters]) + 0.5, cmap.N)\n",
    "clusters_da.unstack().plot(\n",
    "    ax=ax,\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    add_colorbar=False,\n",
    "    add_labels=False\n",
    ")\n",
    "for j in range(n_clu):\n",
    "    lo = clusters_da.lon.where(clusters_da==j).mean().item()\n",
    "    la = clusters_da.lat.where(clusters_da==j).mean().item()\n",
    "    ax.text(lo, la, f\"${j}$\", ha=\"center\", va=\"center\", fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_all_smoothed_anomalies(\"ERA5\", \"plev\", \"s\", \"6H\", 'hourofyear', {'hourofyear': ('win', 4 * 15)}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_all_smoothed_anomalies(\"ERA5\", \"surf\", \"tp\", \"6H\", 'hourofyear', {'hourofyear': ('win', 4 * 15)}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = Path(f\"{DATADIR}/ERA5/surf\")\n",
    "varnames = [\"u10\", \"v10\", \"s10\"]\n",
    "for year, month in tqdm(product(YEARS, range(1, 13)), total=len(YEARS) * 12):\n",
    "    month_str = str(month).zfill(2)\n",
    "    ofiles = {varname: basepath.joinpath(f\"{varname}/6H/{year}{month_str}.nc\") for varname in varnames}\n",
    "    if all([ofile.is_file() for ofile in ofiles.values()]):\n",
    "        continue\n",
    "    ds = xr.open_dataset(basepath.joinpath(f\"raw/{year}{month_str}.nc\"))\n",
    "    ds = ds.rename(longitude=\"lon\", latitude=\"lat\")\n",
    "    ds = ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180))\n",
    "    ds = ds.sortby(\"lon\")\n",
    "    ds = ds.sortby(\"lat\")\n",
    "    ds[\"s10\"] = np.sqrt(ds[\"u10\"] ** 2 + ds[\"v10\"] ** 2)\n",
    "    for varname in varnames:\n",
    "        da = ds[varname]\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=xr.SerializationWarning)\n",
    "            da.to_netcdf(ofiles[varname])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env112",
   "language": "python",
   "name": "env112"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
